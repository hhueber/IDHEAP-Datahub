{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this notebook is to produce an exploitable csv for visualizing the longitudinality of the global questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal Analysis of Global Survey Questions\n",
    "\n",
    "This notebook creates a ready-to-use CSV that links each survey question back to its overarching “global” theme and records when it first appeared—perfect for plotting how key questions have evolved over time. We:\n",
    "\n",
    "1. **Load inputs**  \n",
    "   - Combined raw responses per commune (`commune_responses_combined_raw.csv`)  \n",
    "   - Metadata on our top 10 “global” questions (`top_10_QuestionGlobales_NLP.csv`)  \n",
    "   - Full list of global question labels (`QuestionGlobales_NLP.csv`)\n",
    "\n",
    "2. **Annotate question metadata**  \n",
    "   - Extract the first survey year for each global question code  \n",
    "   - Explode multi-mapped codes to build a mapping dictionary from any sub-question back to its global parent\n",
    "\n",
    "3. **Link responses to global questions**  \n",
    "   - Transpose the response table so question codes become rows  \n",
    "   - Derive a `year` column from each question’s code (e.g., GSB21 → 2021)  \n",
    "   - Map every question in the dataset to its `quest_glob` parent code\n",
    "\n",
    "4. **Standardize multilingual labels**  \n",
    "   - Identify all “spr” columns (label translations)  \n",
    "   - Replace each label with the respondent’s chosen survey language for consistency\n",
    "\n",
    "5. **Export for visualization**  \n",
    "   - Save the final table as `commune_responses_combined.csv`, ready for longitudinal plotting of global question trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined = pd.read_csv(\"../data/commune_responses_combined_raw.csv\", index_col=False)\n",
    "top_10_questions_globales = pd.read_csv(\"../data/top_10_QuestionGlobales_NLP.csv\")\n",
    "full_question_globale_NLP = pd.read_csv(\"../data/QuestionGlobales_NLP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_col = df_commune_responses_combined.columns.get_loc(\"GSB23_Q99\")\n",
    "df_commune_responses_combined = df_commune_responses_combined.iloc[:, start_col:]\n",
    "df_commune_responses_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ajoute une colonne pour chaque question globale avec l'année de la question code_first_question\n",
    "top_10_questions_globales[\"first_year\"] = top_10_questions_globales[\"code_first_question\"].str.extract(r'GSB(\\d{2})').astype(float) + 1900\n",
    "top_10_questions_globales[\"first_year\"] = top_10_questions_globales[\"first_year\"].apply(lambda x: x if x >= 1950 else x + 100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_questions_globales.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transpose le df_combined et rajouter 2 colonnes : 1 qui contient l'année du survey et une colonne qui contient l'id unique de la question globale (si y'en a une associée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined = df_commune_responses_combined.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined = df_commune_responses_combined.iloc[:, :3197]\n",
    "df_commune_responses_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_two_digits(id_str):\n",
    "    if (id_str.startswith(\"GSB\")) or (id_str.startswith(\"spr\")):\n",
    "        match = re.search(r'\\d{2}', id_str)  # Cherche les deux premiers chiffres\n",
    "        return match.group(0) if match else None\n",
    "    else:\n",
    "        # Si l'ID ne commence pas par \"GSB\", on cherche 4 chiffres collés\n",
    "        match = re.search(r'(\\d{4})', id_str)  # Cherche un groupe de 4 chiffres\n",
    "        return match.group(0) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined[\"year\"] = df_commune_responses_combined.index.map(extract_first_two_digits)\n",
    "df_commune_responses_combined[\"year\"] = df_commune_responses_combined[\"year\"].apply(\n",
    "    lambda x: int(x) if pd.notna(x) and len(str(x)) == 4 else (\n",
    "        (int(x) + 1900) if pd.notna(x) and len(str(x)) == 2 and int(x) >= 50 else (\n",
    "            (int(x) + 2000) if pd.notna(x) and len(str(x)) == 2 else None\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "df_commune_responses_combined['year'] = df_commune_responses_combined['year'].fillna(-1).astype(int)\n",
    "df_commune_responses_combined['year'] = df_commune_responses_combined['year'].replace(-1, pd.NA)\n",
    "\n",
    "\n",
    "\n",
    "df_commune_responses_combined.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add column of global question associate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_questions_globales.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploser les valeurs multiples dans `code_other_question`\n",
    "exploded_top_10 = top_10_questions_globales.assign(\n",
    "    code_other_question=top_10_questions_globales['code_other_question'].str.split('; ')\n",
    ").explode('code_other_question')\n",
    "\n",
    "# Créer le dictionnaire de correspondance pour `code_other_question`\n",
    "other_question_mapping = exploded_top_10.set_index('code_other_question')['code_first_question'].to_dict()\n",
    "\n",
    "# Créer self_mapping en accédant directement à la colonne sans set_index\n",
    "self_mapping = dict(zip(top_10_questions_globales['code_first_question'], top_10_questions_globales['code_first_question']))\n",
    "\n",
    "# Combiner les deux dictionnaires\n",
    "mapping_dict = {**other_question_mapping, **self_mapping}\n",
    "\n",
    "# Afficher le dictionnaire final pour vérification\n",
    "print(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined['quest_glob'] = df_commune_responses_combined.index.map(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined = df_commune_responses_combined.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner toutes les colonnes commençant par \"spr\"\n",
    "spr_columns = [col for col in df_commune_responses_combined.columns if col.startswith(\"spr\")]\n",
    "\n",
    "# Remplacer les valeurs des colonnes \"spr\" par les valeurs de \"GSB23_UserLanguage\", sauf pour la ligne \"year\"\n",
    "for col in spr_columns:\n",
    "    df_commune_responses_combined.loc[df_commune_responses_combined.index != 'year', col] = df_commune_responses_combined[\"GSB23_UserLanguage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_columns = [col for col in df_commune_responses_combined.columns if 'spr' in col]\n",
    "print(df_commune_responses_combined[spr_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commune_responses_combined.to_csv('../data/commune_responses_combined.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
